{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfcfa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.8084</td>\n",
       "      <td>0.8694</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.3754</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.2459</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.4283</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.6094</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.4192</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>0.2909</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.5964</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.7969</td>\n",
       "      <td>0.8319</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.8626</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.6048</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.4113</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.4195</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.8067</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>0.7718</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.3862</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.4022</td>\n",
       "      <td>0.4344</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "171  0.0179  0.0136  0.0408  0.0633  0.0596  0.0808  0.2090  0.3465  0.5276   \n",
       "189  0.0158  0.0239  0.0150  0.0494  0.0988  0.1425  0.1463  0.1219  0.1697   \n",
       "20   0.0473  0.0509  0.0819  0.1252  0.1783  0.3070  0.3008  0.2362  0.3830   \n",
       "108  0.0599  0.0474  0.0498  0.0387  0.1026  0.0773  0.0853  0.0447  0.1094   \n",
       "110  0.0210  0.0121  0.0203  0.1036  0.1675  0.0418  0.0723  0.0828  0.0494   \n",
       "\n",
       "         9       10      11      12      13      14      15      16      17  \\\n",
       "171  0.5965  0.6254  0.4507  0.3693  0.2864  0.1635  0.0422  0.1785  0.4394   \n",
       "189  0.1923  0.2361  0.2719  0.3049  0.2986  0.2226  0.1745  0.2459  0.3100   \n",
       "20   0.3759  0.3021  0.2909  0.2301  0.1411  0.1582  0.2430  0.4474  0.5964   \n",
       "108  0.0351  0.1582  0.2023  0.2268  0.2829  0.3819  0.4665  0.6687  0.8647   \n",
       "110  0.0686  0.1125  0.1741  0.2710  0.3087  0.3575  0.4998  0.6011  0.6470   \n",
       "\n",
       "         18      19      20      21      22      23      24      25      26  \\\n",
       "171  0.6950  0.8097  0.8550  0.8717  0.8601  0.9201  0.8729  0.8084  0.8694   \n",
       "189  0.3572  0.4283  0.4268  0.3735  0.4585  0.6094  0.7221  0.7595  0.8706   \n",
       "20   0.6744  0.7969  0.8319  0.7813  0.8626  0.7369  0.4122  0.2596  0.3392   \n",
       "108  0.9361  0.9367  0.9144  0.9162  0.9311  0.8604  0.7327  0.5763  0.4162   \n",
       "110  0.8067  0.9008  0.8906  0.9338  1.0000  0.9102  0.8496  0.7867  0.7688   \n",
       "\n",
       "         27      28      29      30      31      32      33      34      35  \\\n",
       "171  0.8411  0.5793  0.3754  0.3485  0.4639  0.6495  0.6901  0.5666  0.5188   \n",
       "189  1.0000  0.9815  0.7187  0.5848  0.4192  0.3756  0.3263  0.1944  0.1394   \n",
       "20   0.3788  0.4488  0.6281  0.7449  0.7328  0.7704  0.7870  0.6048  0.5860   \n",
       "108  0.4113  0.4146  0.3149  0.2936  0.3169  0.3149  0.4132  0.3994  0.4195   \n",
       "110  0.7718  0.6268  0.4301  0.2077  0.1198  0.1660  0.2618  0.3862  0.3958   \n",
       "\n",
       "         36      37      38      39      40      41      42      43      44  \\\n",
       "171  0.5060  0.3885  0.3762  0.3738  0.2605  0.1591  0.1875  0.2267  0.1577   \n",
       "189  0.1670  0.1275  0.1666  0.2574  0.2258  0.2777  0.1613  0.1335  0.1976   \n",
       "20   0.6385  0.7279  0.6286  0.5316  0.4069  0.1791  0.1625  0.2527  0.1903   \n",
       "108  0.4532  0.4419  0.4737  0.3431  0.3194  0.3370  0.2493  0.2650  0.1748   \n",
       "110  0.3248  0.2302  0.3250  0.4022  0.4344  0.4008  0.3370  0.2518  0.2101   \n",
       "\n",
       "         45      46      47      48      49      50      51      52      53  \\\n",
       "171  0.1211  0.0883  0.0850  0.0355  0.0219  0.0086  0.0123  0.0060  0.0187   \n",
       "189  0.1234  0.1554  0.1057  0.0490  0.0097  0.0223  0.0121  0.0108  0.0057   \n",
       "20   0.1643  0.0604  0.0209  0.0436  0.0175  0.0107  0.0193  0.0118  0.0064   \n",
       "108  0.0932  0.0530  0.0081  0.0342  0.0137  0.0028  0.0013  0.0005  0.0227   \n",
       "110  0.1181  0.1150  0.0550  0.0293  0.0183  0.0104  0.0117  0.0101  0.0061   \n",
       "\n",
       "         54      55      56      57      58      59 60  \n",
       "171  0.0111  0.0126  0.0081  0.0155  0.0160  0.0085  M  \n",
       "189  0.0028  0.0079  0.0034  0.0046  0.0022  0.0021  M  \n",
       "20   0.0042  0.0054  0.0049  0.0082  0.0028  0.0027  R  \n",
       "108  0.0209  0.0081  0.0117  0.0114  0.0112  0.0100  M  \n",
       "110  0.0031  0.0099  0.0080  0.0107  0.0161  0.0133  M  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Dropout Regularization\\\\sonar_dataset.csv\",header=None)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbc5a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "56    False\n",
       "57    False\n",
       "58    False\n",
       "59    False\n",
       "60    False\n",
       "Length: 61, dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0b47f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()    #binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0916d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(60,axis=1) \n",
    "y = df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe50665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "127  0\n",
       "162  0\n",
       "5    1\n",
       "176  0\n",
       "144  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y,drop_first=True)\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11446f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c251d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,train_size=0.75,random_state=10)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61933f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8c0534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 3ms/step - loss: 0.6795 - accuracy: 0.5705\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7179\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7308\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7308\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7564\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7756\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.8205\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8526\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8590\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8846\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8654\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8526\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8846\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8718\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8910\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.8910\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8846\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8654\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9038\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9487\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9423\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9487\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9423\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9679\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9744\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9551\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9808\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9487\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9679\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9872\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9936\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9936\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9615\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9359\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9872\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9936\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9936\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9808\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2703bbe7ee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60 , input_dim=60, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eaeb8f",
   "metadata": {},
   "source": [
    "# This model is overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e99f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5347 - accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.534691572189331, 0.7692307829856873]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962a0f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9999630e-01 9.9998868e-01 1.8973383e-01 4.6846256e-09 9.9999440e-01\n",
      " 6.1362809e-01 9.9943727e-01 1.5998792e-02 4.5703677e-05 9.9847049e-01]\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b2efb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "58   1\n",
       "63   1\n",
       "35   1\n",
       "19   1\n",
       "59   1\n",
       "56   1\n",
       "83   1\n",
       "105  0\n",
       "121  0\n",
       "76   1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb971530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        26\n",
      "           1       0.77      0.77      0.77        26\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.77      0.77      0.77        52\n",
      "weighted avg       0.77      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e720d7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7747 - accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5641\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.5577\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5321\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5128\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5449\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.5385\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5192\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.5385\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5769\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5641\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5192\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.5897\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.4936\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6538\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5962\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5833\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.6090\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5513\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5705\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6282\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5962\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6282\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6218\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6154\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6218\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6538\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6090\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6795\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7051\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6154\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6538\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6603\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6795\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6795\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7051\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7179\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.6859\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7308\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7244\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6923\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7692\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7564\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7308\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7628\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7179\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7244\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7372\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7821\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7564\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7564\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8141\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7628\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8141\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7564\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8205\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8141\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7628\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7949\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8013\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8141\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8013\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.7885\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8397\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8013\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8397\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8077\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8782\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8526\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8205\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8462\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8462\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8654\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8269\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8590\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8718\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8462\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8654\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8526\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8141\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8654\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8526\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8397\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8462\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8397\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8269\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8590\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8269\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9103\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8718\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8782\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8782\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8269\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2709202c760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60 , input_dim=60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),        #drop 50% of neurons\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),           #we can drop any amount of neurons\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(optimizer='adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "modeld.fit(X_train,y_train,epochs=100,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "359f4e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6078478097915649, 0.7692307829856873]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ddc0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9993013  0.99842644 0.64576244 0.00408651 0.998553   0.5343627\n",
      " 0.6636053  0.39122462 0.18724746 0.9550489 ]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeld.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a26bde0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        26\n",
      "           1       0.77      0.77      0.77        26\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.77      0.77      0.77        52\n",
      "weighted avg       0.77      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a7a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
